{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root='../../datasets/CIFAR10', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "trainset.train_data = np.concatenate((trainset.train_data, trainset.train_data[::-1, :]))\n",
    "trainset.train_labels = np.concatenate((trainset.train_labels, trainset.train_labels[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = datasets.CIFAR10(root='../../datasets/CIFAR10', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # 3 x 32 x 32\n",
    "            nn.Conv2d(3, 10, 3, 1, 1),\n",
    "#             nn.BatchNorm2d(10),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 10 x 32 x 32\n",
    "            nn.Conv2d(10, 32, 3, 1, 1),\n",
    "#             nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 32 x 32 x 32\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # 32 x 16 x 16\n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "#             nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 64 x 16 x 16\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # 64 x 8 x 8\n",
    "            nn.Conv2d(64, 10, 3, 1, 1),\n",
    "#             nn.BatchNorm2d(10),\n",
    "            nn.LeakyReLU(0.2)\n",
    "            \n",
    "            \n",
    "            # output ==> 10 x 8 x 8\n",
    "        )\n",
    "        \n",
    "        # 10 x 8 x 8\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        \n",
    "        # 10 x 1 x 1\n",
    "        self.fc = nn.Linear(10, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.conv(x)\n",
    "        flatten = self.avg_pool(features).view(features.size(0), -1)\n",
    "        output = self.fc(flatten)\n",
    "        \n",
    "        return output, features\n",
    "    \n",
    "model = Net().cuda()\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==> Training Start\n",
      "\n",
      " epoch 1 1452.2392163872719\n",
      "\n",
      " epoch 2 1077.4625252485275\n",
      "\n",
      " epoch 3 956.4936799108982\n",
      "\n",
      " epoch 4 878.1891563534737\n",
      "\n",
      " epoch 5 817.8192512392998\n",
      "\n",
      " epoch 6 777.3869813680649\n",
      "\n",
      " epoch 7 736.9774436950684\n",
      "\n",
      " epoch 8 712.5183827579021\n",
      "\n",
      " epoch 9 691.1017688810825\n",
      "\n",
      " epoch 10 658.5683560967445\n",
      "Elapsed Time : 150.008\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print('\\n ==> Training Start')\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    total_loss =  0.0\n",
    "    \n",
    "#     for data, target in train_loader:\n",
    "    for data, target in train_loader:\n",
    "        train_x, train_y = Variable(data.float()).cuda(), Variable(target.long()).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(train_x)\n",
    "        loss = criterion(outputs, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print('\\n epoch %d' % (epoch+1), total_loss)\n",
    "end = time.time()\n",
    "\n",
    "print('Elapsed Time : %.3f' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc : 71.070\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data, target in test_loader:\n",
    "    test_x, test_y = Variable(data).cuda(), Variable(target).cuda()\n",
    "    outputs, _ = model(test_x)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    total += test_y.size(0)\n",
    "    correct += (predicted.cpu() == test_y.cpu()).sum().item()\n",
    "\n",
    "print('Acc : %.3f' % ((correct/total) * 100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 75 %\n",
      "Accuracy of   car : 87 %\n",
      "Accuracy of  bird : 50 %\n",
      "Accuracy of   cat : 55 %\n",
      "Accuracy of  deer : 77 %\n",
      "Accuracy of   dog : 68 %\n",
      "Accuracy of  frog : 67 %\n",
      "Accuracy of horse : 78 %\n",
      "Accuracy of  ship : 81 %\n",
      "Accuracy of truck : 82 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        images, labels = Variable(data).cuda(), Variable(target).cuda()\n",
    "        outputs, _ = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted.cpu() == labels.cpu()).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x1b319cbe358>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_conv = 'conv'\n",
    "\n",
    "#hook (원하는 위치의 gradient값)\n",
    "feature_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    feature_blobs.append(output.cpu().data.numpy())\n",
    "    \n",
    "model._modules.get(final_conv).register_forward_hook(hook_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.parameters())\n",
    "\n",
    "weight_softmax = np.squeeze(params[-2].cpu().data.numpy())\n",
    "\n",
    "\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    size_upsample = (32, 32)\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "    cam = cam.reshape(h, w)\n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    cam_img = np.uint8(255 * cam_img)\n",
    "    output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    \n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./result'):\n",
    "    os.mkdir('result/')\n",
    "\n",
    "test_batch = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 ship 0.998473584651947\n"
     ]
    }
   ],
   "source": [
    "image_tensor, image_label = test_batch.next()\n",
    "image_PIL = transforms.ToPILImage()(image_tensor[0])\n",
    "image_PIL.save('./result/test.jpg')\n",
    "\n",
    "image_tensor = Variable(image_tensor).cuda()\n",
    "logit, _ = model(image_tensor)\n",
    "h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "probs, idx = h_x.sort(0, True)\n",
    "print(idx[0].item(), classes[idx[0]], probs[0].item())\n",
    "CAMs = returnCAM(feature_blobs[0], weight_softmax, [idx[0].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('result/test.jpg')\n",
    "height, width, _ = img.shape\n",
    "heatmap = cv2.applyColorMap(cv2.resize(CAMs[0], (width, height)), cv2.COLORMAP_JET)\n",
    "result = heatmap * 1 + img * 0\n",
    "cv2.imwrite('result/CAM.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b31ea85908>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = image_tensor.cpu().numpy().squeeze()\n",
    "print(img.shape)\n",
    "plt.imshow(np.transpose(img, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 8, 8)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_blobs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
