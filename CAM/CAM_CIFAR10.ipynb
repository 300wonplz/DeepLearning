{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10(root='../../CIFAR10', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "trainset.train_data = np.concatenate((trainset.train_data, trainset.train_data[::-1, :]))\n",
    "trainset.train_labels = np.concatenate((trainset.train_labels, trainset.train_labels[::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = datasets.CIFAR10(root='../../CIFAR10', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # 3 x 32 x 32\n",
    "            nn.Conv2d(3, 10, 3, 1, 1),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 10 x 32 x 32\n",
    "            nn.Conv2d(10, 32, 3, 1, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 32 x 32 x 32\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # 32 x 16 x 16\n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 64 x 16 x 16\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # 64 x 8 x 8\n",
    "            nn.Conv2d(64, 10, 3, 1, 1),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.LeakyReLU(0.2)\n",
    "            \n",
    "            # output ==> 10 x 8 x 8\n",
    "        )\n",
    "        \n",
    "        # 10 x 8 x 8\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        \n",
    "        # 10 x 1 x 1\n",
    "        self.fc = nn.Linear(10, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.conv(x)\n",
    "        flatten = self.avg_pool(features).view(features.size(0), -1)\n",
    "        output = self.fc(flatten)\n",
    "        \n",
    "        return output, features\n",
    "    \n",
    "model = Net().cuda()\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==> Training Start\n",
      "\n",
      " epoch 1 0.39012473034650086\n",
      "\n",
      " epoch 2 0.31450540833428503\n",
      "\n",
      " epoch 3 0.28624165576905014\n",
      "Elapsed Time : 843.740\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print('\\n ==> Training Start')\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    total_loss =  0.0\n",
    "    \n",
    "#     for data, target in train_loader:\n",
    "    for data, target in train_loader:\n",
    "        train_x, train_y = Variable(data.float()).cuda(), Variable(target.long()).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(train_x)\n",
    "        loss = criterion(outputs, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print('\\n epoch %d' % (epoch+1), total_loss/trainset.train_data.shape[0])\n",
    "end = time.time()\n",
    "\n",
    "print('Elapsed Time : %.3f' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc : 60.650\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data, target in test_loader:\n",
    "    test_x, test_y = Variable(data).cuda(), Variable(target).cuda()\n",
    "    outputs, _ = model(test_x)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    total += test_y.size(0)\n",
    "    correct += (predicted.cpu() == test_y.cpu()).sum().item()\n",
    "\n",
    "print('Acc : %.3f' % ((correct/total) * 100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 60 %\n",
      "Accuracy of   car : 79 %\n",
      "Accuracy of  bird : 43 %\n",
      "Accuracy of   cat : 26 %\n",
      "Accuracy of  deer : 59 %\n",
      "Accuracy of   dog : 58 %\n",
      "Accuracy of  frog : 62 %\n",
      "Accuracy of horse : 64 %\n",
      "Accuracy of  ship : 72 %\n",
      "Accuracy of truck : 78 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        images, labels = Variable(data).cuda(), Variable(target).cuda()\n",
    "        outputs, _ = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted.cpu() == labels.cpu()).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x27b82b21ac8>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_conv = 'conv'\n",
    "\n",
    "#hook (원하는 위치의 gradient값)\n",
    "feature_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    feature_blobs.append(output.cpu().data.numpy())\n",
    "    \n",
    "model._modules.get(final_conv).register_forward_hook(hook_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.parameters())\n",
    "\n",
    "weight_softmax = np.squeeze(params[-2].cpu().data.numpy())\n",
    "\n",
    "\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    size_upsample = (32, 32)\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "    cam = cam.reshape(h, w)\n",
    "    cam = cam - np.min(cam)\n",
    "    cam_img = cam / np.max(cam)\n",
    "    cam_img = np.uint8(255 * cam_img)\n",
    "    output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    \n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./result'):\n",
    "    os.mkdir('result/')\n",
    "\n",
    "test_batch = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 deer 0.22546671330928802\n"
     ]
    }
   ],
   "source": [
    "image_tensor, image_label = test_batch.next()\n",
    "image_PIL = transforms.ToPILImage()(image_tensor[0])\n",
    "image_PIL.save('./result/test.jpg')\n",
    "\n",
    "image_tensor = Variable(image_tensor).cuda()\n",
    "logit, _ = model(image_tensor)\n",
    "h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "probs, idx = h_x.sort(0, True)\n",
    "print(idx[0].item(), classes[idx[0]], probs[0].item())\n",
    "CAMs = returnCAM(feature_blobs[0], weight_softmax, [idx[0].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('result/test.jpg')\n",
    "height, width, _ = img.shape\n",
    "heatmap = cv2.applyColorMap(cv2.resize(CAMs[0], (width, height)), cv2.COLORMAP_JET)\n",
    "result = heatmap * 0.3 + img * 0.5\n",
    "cv2.imwrite('result/CAM.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27c31d68240>"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = image_tensor.cpu().numpy().squeeze()\n",
    "print(img.shape)\n",
    "plt.imshow(np.transpose(img, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 8, 8)"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_blobs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
