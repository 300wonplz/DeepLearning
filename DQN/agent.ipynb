{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from game import Game\n",
    "from model import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_boolean(\"train\", False, \"학습모드, 게임을 화면에 보여주지 않습니다.\")\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPISODE=10000\n",
    "TARGET_UPDATE_INTERVAL = 1000\n",
    "TRAIN_INTERVAL = 4\n",
    "OBSERVE = 100\n",
    "NUM_ACTION = 3\n",
    "SCREEN_WIDTH = 6\n",
    "SCREEN_HEIGHT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    print(\"뇌세포 깨우는 중..\")\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    game = GAME(SCREEN_WIDTH, SCREEN_HEIGHT, shoe_game = False)\n",
    "    brain = DQN(ses, SCREEN_WIDTH, SCREEN_HEIGHT, NUM_ACTION)\n",
    "    rewards = tf.placeholder(tf.float32, [None])\n",
    "    tf.summary.scaler('avg.reward/ep.', tf.reduce_mean(rewards))\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer)\n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    summary_merged = tf.summary.merge_all\n",
    "    \n",
    "    brain.update_target_network()\n",
    "    epsilon = 1.0\n",
    "    \n",
    "    time_step = 0\n",
    "    total_reward_list = []\n",
    "    \n",
    "    for episode in range(MAX_EPISODE):\n",
    "        terminal = False\n",
    "        total_reward = 0\n",
    "        \n",
    "        state= game.reset()\n",
    "        brain.init_state(state)\n",
    "    \n",
    "        while not terminal:\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = random.randrange(NUM_ATION)\n",
    "            else:\n",
    "                action = brain.get_action()\n",
    "                \n",
    "            if episode > OBSERVE:\n",
    "                rpdilon -= 1/1000\n",
    "                \n",
    "            state, reward, terminal = game.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            brain.remember(state, action, reward, terminal)\n",
    "            \n",
    "            if time_step > OBSERVE and time_step % TRAIN_INTERVAL == 0:\n",
    "                brain.train()\n",
    "            \n",
    "            if time_step % TARGET_UPDATE_INTERVAL == 0:\n",
    "                brain.update_target_network()\n",
    "                \n",
    "            time_step += 1\n",
    "            \n",
    "            print('게임횟수 : %d, 점수 :  %d' % (episode+1, total_reward))\n",
    "            \n",
    "            total_reward_list.append(total_reward)\n",
    "            \n",
    "            if episode % 10 == 0:\n",
    "                summary = sess.run(summary_merged, feed_dict={rewards: total_reward_list})\n",
    "                writer.add_summary(summary, time_step)\n",
    "                total_reward_list = []\n",
    "                \n",
    "            if episode % 100 ==0:\n",
    "                saver.save(sess, 'model/dqn.ckpt', global_step=time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay():\n",
    "    print(\"뇌세포 깨우는 중..\")\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    game = GAME(SCREEN_WIDTH, SCREEN_HEIGHT, shoe_game = True)\n",
    "    brain = DQN(ses, SCREEN_WIDTH, SCREEN_HEIGHT, NUM_ACTION)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    ckpt = tf.train.get_checkpoint_state('model1')\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    \n",
    "    for episode in range(MAX_EPISODE):\n",
    "        terminal = False\n",
    "        total_reward = 0\n",
    "        \n",
    "        state = game.reset()\n",
    "        brain.init_state(state)\n",
    "        \n",
    "        while not terminal:\n",
    "            action = brain.get_action()\n",
    "            \n",
    "            state, reward, terminal = game.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            brain.remember(state, action, reward, terminal)\n",
    "            \n",
    "            time.sleep(0.3)\n",
    "            \n",
    "        print('게임횟수: %d  점수: %d' % (episode +1, total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뇌세포 깨우는 중..\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'GAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ba4aed7a6b08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\whgud\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-ba4aed7a6b08>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mreplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-53ac4e0dd2bd>\u001b[0m in \u001b[0;36mreplay\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mgame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGAME\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSCREEN_WIDTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSCREEN_HEIGHT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshoe_game\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mbrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSCREEN_WIDTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSCREEN_HEIGHT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_ACTION\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GAME' is not defined"
     ]
    }
   ],
   "source": [
    "def main(_):\n",
    "    if FLAGS.train:\n",
    "        train()\n",
    "    else:\n",
    "        replay()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
